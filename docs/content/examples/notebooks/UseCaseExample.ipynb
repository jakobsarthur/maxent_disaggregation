{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Cases and Examples for maxent_disaggregation\n",
    "\n",
    "The `maxent_disaggregation` package enables statistically sound disaggregation of aggregate data with uncertainty propagation. When disaggregating data (splitting a total into components), the components are naturally correlated. These correlations must be properly accounted for in uncertainty analysis to avoid mis-estimating uncertainty in downstream calculations.\n",
    "\n",
    "This notebook demonstrates how to use `maxent_disaggregation` through a practical example in Industrial Ecology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Carbon Footprint of Steel in Vehicle Manufacturing\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "An Industrial Ecology researcher has data on total steel consumption for vehicle manufacturing but needs to disaggregate this figure by vehicle type (ICE, BEV, and HBEV) based on production volume proxies. A second researcher will use these disaggregated figures for Life Cycle Assessment (LCA).\n",
    "\n",
    "![Figure 1: A diagram of the example](images/example_steel.png)\n",
    "\n",
    "Properly accounting for correlations between the disaggregated values is critical for accurate uncertainty estimation in the LCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available Information\n",
    "\n",
    "The researcher has:\n",
    "\n",
    "1. A best estimate for total steel consumption: 100 tonnes/year\n",
    "2. An uncertainty estimate for that total: standard deviation of 3 tonnes/year\n",
    "3. A natural lower bound of 0 (no negative consumption)\n",
    "4. Proxy-based estimates of shares by vehicle type: ICE (80%), BEV (19%), HBEV (1%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Correlated Samples with maxent_disaggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from maxent_disaggregation import maxent_disagg\n",
    "import seaborn as sns\n",
    "\n",
    "# Set parameters\n",
    "n_samples = 10000\n",
    "mean_aggregate = 100  # Best estimate for total\n",
    "sd_aggregate = 3      # Standard deviation for total\n",
    "shares = [0.8, 0.19, 0.01]  # Proxy-based estimates of shares\n",
    "vehicle_types = [\"ICE\", \"BEV\", \"HBEV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate correlated samples\n",
    "samples, _, _, _ = maxent_disagg(\n",
    "    n=n_samples,\n",
    "    mean_0=mean_aggregate,\n",
    "    sd_0=sd_aggregate,\n",
    "    min_0=0,  # Lower bound\n",
    "    shares=shares,\n",
    "    log=True  # Use log-normal distribution for sampling\n",
    ")\n",
    "\n",
    "# Convert samples to a DataFrame for easier analysis\n",
    "samples_df = pd.DataFrame(samples, columns=vehicle_types)\n",
    "samples_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Distribution of Each Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms for each vehicle type\n",
    "samples_df.melt(var_name=\"Vehicle Type\", value_name=\"Steel Consumption\").pipe(\n",
    "    (sns.histplot, \"data\"),\n",
    "    x=\"Steel Consumption\",\n",
    "    hue=\"Vehicle Type\",\n",
    "    kde=True,\n",
    "    bins=100,\n",
    "    alpha=0.3\n",
    ").set(\n",
    "    xlabel=\"Steel Consumption (tonnes)\",\n",
    "    ylabel=\"Frequency\",\n",
    "    title=\"Distribution of Steel Consumption by Vehicle Type\"\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating the Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the total matches our specified mean and SD\n",
    "sample_total = samples_df.sum(axis=1)\n",
    "print(\"Mean of the sampled total:\", sample_total.mean())\n",
    "print(\"SD of the sampled total:\", sample_total.std())\n",
    "\n",
    "# Check if shares match our specified values\n",
    "sample_shares = samples_df.div(sample_total, axis=0)\n",
    "print(\"Means of the sampled shares:\", sample_shares.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Correlations in the Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlations\n",
    "sns.pairplot(samples_df, kind=\"reg\", diag_kind=\"kde\", plot_kws={\"scatter_kws\": {\"alpha\": 0.1}})\n",
    "plt.suptitle(\"Correlations Between Vehicle Type Steel Consumption\", y=1.02);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downstream Analysis: LCA of Carbon Footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set emission factor\n",
    "emission_factor_steel = 2.5\n",
    "\n",
    "# Calculate emissions using correlated samples\n",
    "sample_emissions_full = samples_df * emission_factor_steel\n",
    "total_emissions_full = sample_emissions_full.sum(axis=1)\n",
    "\n",
    "print(\"Mean emissions:\", total_emissions_full.mean(), \"tonnes CO₂\")\n",
    "print(\"SD emissions:\", total_emissions_full.std(), \"tonnes CO₂\")\n",
    "print(\"CV emissions:\", total_emissions_full.std() / total_emissions_full.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Results with Independent Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent sampling ignoring correlations\n",
    "independent_samples = pd.DataFrame({\n",
    "    \"ICE\": np.random.normal(loc=shares[0] * mean_aggregate, scale=sd_aggregate * shares[0], size=n_samples),\n",
    "    \"BEV\": np.random.normal(loc=shares[1] * mean_aggregate, scale=sd_aggregate * shares[1], size=n_samples),\n",
    "    \"HBEV\": np.random.normal(loc=shares[2] * mean_aggregate, scale=sd_aggregate * shares[2], size=n_samples)\n",
    "})\n",
    "\n",
    "# Calculate emissions using independent samples\n",
    "sample_emissions_independent = independent_samples * emission_factor_steel\n",
    "total_emissions_independent = sample_emissions_independent.sum(axis=1)\n",
    "\n",
    "print(\"Mean emissions (independent):\", total_emissions_independent.mean(), \"tonnes CO₂\")\n",
    "print(\"SD emissions (independent):\", total_emissions_independent.std(), \"tonnes CO₂\")\n",
    "print(\"CV emissions (independent):\", total_emissions_independent.std() / total_emissions_independent.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine results for comparison\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"Emissions\": np.concatenate([total_emissions_full, total_emissions_independent]),\n",
    "    \"Approach\": [\"With Correlations\"] * len(total_emissions_full) + [\"Independent Sampling\"] * len(total_emissions_independent)\n",
    "})\n",
    "\n",
    "# Plot comparison\n",
    "sns.histplot(data=comparison_df, x=\"Emissions\", hue=\"Approach\", kde=True, bins=50, alpha=0.5)\n",
    "plt.xlabel(\"Total Emissions (tonnes CO₂)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Impact of Correlations on Uncertainty Estimation\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The `maxent_disaggregation` package provides a simple interface for generating statistically valid samples of disaggregated data while properly accounting for correlations. This is crucial for accurate uncertainty propagation in subsequent analyses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}